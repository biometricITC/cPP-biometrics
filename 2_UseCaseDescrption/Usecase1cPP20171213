collaborative Protection Profile

for

Biometric verification on the mobile device

- for unlocking the device -

Version 0.1

24-OCT-2017

Note: This is a cPP for mobile use case 1 (EAL1+). cPP for use case 2
will be created adding SFRs and assurance activities to this cPP.

This is a preliminary version and text marked in yellow will be updated
or modified.

Acknowledgements

This collaborative Protection Profile (cPP) was developed by the
Biometrics Security (BS) international Technical Community (iTC) with
representatives from industry, Government agencies, Common Criteria Test
Laboratories, and members of academia.

Preface
=======

Objective of Document
---------------------

This document presents the Common Criteria (CC) collaborative Protection
Profile (cPP) to express the security functional requirements (SFRs) and
security assurance requirements (SARs) for a biometric verification on
the mobile device. The Evaluation activities that specify the actions
the evaluator performs to determine if a product satisfies the SFRs
captured within this cPP are described in \[SD\].

Note: Evaluation activities are included in this document to make it
easy to review them. However, they will be moved to \[SD\].

Scope of Document
-----------------

The scope of the cPP within the development and evaluation process is
described in the Common Criteria for Information Technology Security
Evaluation \[CC\]. In particular, a cPP defines the IT security
requirements of a generic type of TOE and specifies the functional and
assurance security measures to be offered by that TOE to meet stated
requirements \[CC1, Section C.1\].

Intended Readership
-------------------

The target audiences of this cPP are developers, CC consumers, system
integrators, evaluators and schemes.

Although the cPPs and SDs may contain minor editorial errors, cPPs are
recognized as living documents and the iTCs are dedicated to ongoing
updates and revisions. Please report any issues to the BS iTC.

Related Documents
-----------------

**Common Criteria**

\[CC1\] Common Criteria for Information Technology Security Evaluation,

> Part 1: Introduction and General Model,
>
> CCMB-2017-04-001, Version 3.1 Revision 5, April 2017.

\[CC2\] Common Criteria for Information Technology Security Evaluation,

> Part 2: Security functional components,
>
> CCMB-2017-04-002, Version 3.1 Revision 5, April 2017.

\[CC3\] Common Criteria for Information Technology Security Evaluation,

> Part 3: Security assurance components,
>
> CCMB-2017-04-003, Version 3.1 Revision 5, April 2017.

\[CEM\] Common Methodology for Information Technology Security
Evaluation,

> Evaluation Methodology,
>
> CCMB-2017-04-004, Version 3.1 Revision 5, April 2017.

**Other document**

\[SD\] Evaluation Activities for Biometric verification on the mobile
devices \[TBD\]

Glossary
--------

For the purposes of this cPP, the following terms and definitions given
in ISO/IEC 19795-1:2006 and Protection Profile for Mobile Device
Fundamentals \[MDF PP\] Version 3.1 apply. Terms and definitions given
in \[MDF PP\] are modified to fit to ISO/IEC 19795-1:2006.

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Term                     Definition
  ------------------------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Adaptive (template)      Authentication templates that evolve with each sample that is verified and introduced into the biometrics database or gallery.

  Sample                   User’s biometric measures as output by the data capture subsystem
                           
                           EXAMPLE Fingerprint image, face image and iris image are samples.

  Features                 Digital representation of the information extracted from a sample (by the signal processing subsystem) that will be used to construct or compare against enrolment templates
                           
                           EXAMPLE Minutiae coordinates and principal component coefficients are features.

  Template                 User’s stored reference measure based on features extracted from enrolment samples

  Matching score           Measure of the similarity between features derived from a sample and a stored template, or a measure of how well these features fit a user’s reference model
                           
                           NOTE 1 A match or non-match decision may be made according to whether this score exceeds a decision threshold.
                           
                           NOTE 2 As features derived from a presented sample become closer to the stored template, similarity scores will increase.

  Biometric verification   Application in which the user makes a positive claim to an identity, features derived from the submitted sample biometric measure are compared to the enrolled template for the claimed identity, and an accept or reject decision regarding the identity claim is returned
                           
                           NOTE The claimed identity might be in the form of a name, personal identification number (PIN), swipe card, or other unique identifier provided to the system.

  TBD                      TBD

                           

                           

                           

                           

                           

                           
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Revision history
----------------

  Version   Date               Description
  --------- ------------------ ----------------------------------------------
  0.1       24^th^ Oct, 2017   Preliminary draft for the Berlin iTC session
                               

PP Introduction
===============

PP Reference Identification
---------------------------

PP Reference: collaborative Protection Profile for Biometric
verification on the mobile devices - for unlocking the device -

PP Version: 0.1

PP Date: 24-OCT-2017

TOE Overview
------------

This is a collaborative Protection Profile (cPP) whose Target of
Evaluation (TOE) is integrated into a mobile device and enrolls and
verifies users using their biometric characteristics. Each biometric
enrolment and verification process is described in the following
paragraphs.

a)  Biometric enrolment

During the enrolment process, the TOE captures samples from the
biometric characteristics of users presented to the TOE and extracts the
features from the samples. The features are then stored as enrolment
templates in the TOE. The enrolment templates may be updated later to
authentication templates using verified samples for adapting changes of
the users’ biometric characteristic caused by, for example, aging.

a)  Biometric verification

During the verification process users present their biometric
characteristics to the TOE. The TOE retrieves the templates and compares
them with the features extracted from the captured samples of users to
measure the similarity between the two data, and determines whether
users are accepted or rejected based on the similarity.

Examples of biometric characteristic used by the TOE are: fingerprint,
face, iris, palm print, finger vein, palm vein, speech, signature and so
forth.

The TOE needs to consider the risk of subverting the TOE’s biometric
verification. Attacker could present artificial or abnormal biometric
characteristics to the TOE to interfere with the TOE’s security
objectives. Such attack is called presentation attack and the TOE needs
to provide Presentation Attack Detection (PAD) functionality to counter
such attack.

TOE Design
----------

The TOE is fully integrated into the mobile device without the need for
additional software and hardware. The TOE is composed of multiple
individual components (such as sensor and matching algorithm) and
capable of:

-   Capturing samples from users’ biometric characteristics

-   Extracting and processing the features from samples

-   Generating various templates based on processing of any samples or
    features during enrolment, and if adaptive, during verifications as
    well

-   Storing the extracted information in a database on the mobile device

-   Comparing captured features with data contained in one or more
    authentication templates

-   Deciding how well features and any template match and indicating
    whether or not a verification of identity has been achieved

When considering mobile devices, the TOE is reliant on the device itself
to provide overall security of the system (such for security
communications, storage and audit). The evaluation of the mobile device
security is expected to be performed separately and out of scope of this
cPP.

TOE Use Case
------------

Mobile device itself may be operated in a number of use cases such as
enterprise use with limited personal use or Bring Your Own Device
(BYOD). The TOE on the device may also be operated in the same use cases
however use cases of the TOE should be devised separately considering
the purpose of biometric verification and potential attacks. The
following use cases describe how and why biometric verification is
supposed to be used. Each use case has its own assurance level depending
on its criticality and separate cPP is developed for each use case.

USE CASE 1: collaborative Protection Profile for Biometric verification
on the mobile devices - for unlocking the device – (This document)

-   Assurance level of this cPP is EAL1+ and defines minimum level of
    assurance activities

USE CASE 2: collaborative Protection Profile for Biometric verification
on the mobile devices - for security sensitive service -

-   Assurance level of this cPP is EAL2+ because it requires evaluator’s
    independent performance testing and more in-depth vulnerability
    analysis than the USE CASE 1

\[USE CASE 1: Mobile device biometric verification on “unlocked”
device\]

For enhanced security that is easy to use, mobile devices may implement
biometric verification on a device once it has been “unlocked”. The
initial unlock is generally done by a PIN/password which is required at
startup (or possibly after some period of time) and after that the user
is able to use an own biometric characteristic to unlock access to the
device. Mobile device is not supposed to be used for security sensitive
services as described in the USE CASE 2 through the biometric
verification.

Main concern of this use case is the biometric performance (FAR and FRR)
and ensuring access cannot be bypassed. Security assurance for mobile
device itself should be handled through another CC evaluation (e.g.
evaluation based on \[MDF PP\]).

This use case assumes that the mobile devices are configured correctly
to enable the biometric verification by the biometric system
administrator. The users can act as the biometric system administrator
in this use case. In both cases, the biometric system administrator is
assumed to be trustworthy.

It is also assumed that the users enroll themselves correctly at secure
environment following the guidance provided by the TOE. Attacks during
enrolments are out of scope and FTE is not security relevant performance
matrix for this use case.

\[USE CASE 2: Mobile device biometric verification for security
sensitive service\]

Mobile devices may be used for security sensitive service such as
payment transactions and online banking. Verification may be done by the
biometric for convenience instead of PIN/password to access such
security sensitive services.

The requirements for the TOE focus on the biometric performance (FTE,
FAR and FRR) and presentation attack. Security assurance for mobile
device itself should be handled through another CC evaluation (e.g.
evaluation based on \[MDF PP\]).

CC Conformance
==============

As defined by the references \[CC1\], \[CC2\] and \[CC3\], this cPP:

-   conforms to the requirements of Common Criteria v3.1, Revision 5

-   is Part 2 extended, Part 3 conformant

-   does not claim conformance to any other PP.

The methodology applied for the cPP evaluation is defined in \[CEM\].
This cPP satisfies the following Assurance Families:

APE\_CCL.1, APE\_ECD.1, APE\_INT.1, APE\_OBJ.1, APE\_REQ.1 and
APE\_SPD.1.

In order to be conformant to this cPP, a TOE must demonstrate Exact
Conformance. Exact Conformance, as a subset of Strict Conformance as
defined by the CC, is defined as the ST containing all of the SFRs in
section 6 (these are the mandatory SFRs) of this cPP, and potentially
SFRs from Appendix X (these are optional SFRs) of this cPP. While
iteration is allowed, no additional requirements (from the CC parts 2 or
3, or definitions of extended components not already included in this
cPP) are allowed to be included in the ST. Further, no SFRs in section 6
of this cPP are allowed to be omitted.

Security Problem Definition
===========================

Threats
-------

#### T.Casual\_Attack 

An attacker may attempt to impersonate as a legitimate user without
being enrolled in the TOE. In order to perform the attack, the attackers
only use their own biometric characteristic (in form of a
zero-effort-attack).

#### T.Presentation\_Attack

An attacker may attempt a presentation attack to the TOE. In order to
perform the attack, the attacker uses any Presentation Attack Instrument
(PAI) except their own biometric characteristic.

Application note:

Acquisition of biometric characteristic may be cooperative or
non-cooperative.

The TOE may or may not counter the presentation attack during the
enrollment. If the ST author requires the TOE to counter the attack
during the enrollment, ST author should include relevant optional
security requirement defined in “6.2 Optional Security Fundamental
Requirements”.

Organizational Security Policies
--------------------------------

#### OSP.Enrol

The TOE shall enroll users for biometric verification, only after
successful authentication of a user. The TOE shall ensure that enrolment
templates are of sufficient quality in order to meet the requirements on
recognition performance.

#### OSP.Verification\_Error

The TOE shall meet relevant criteria for its security relevant error
rates for biometric verification.

#### OSP.PAD\_Error

The TOE shall meet relevant criteria for its security relevant error
rates for PAD.

#### OSP.TrialLimit

The TOE in cooperation with its environment must prevent impostors from
gaining access to the protected services by limiting the ability to make
repeated verification attempts using one or more claimed user IDs.

Assumptions
-----------

#### A.User

It is assumed that the user configures the device correctly in a manner
to ensure that the TOE security policies will be enforced.

#### A.Alternative

It is assumed that an alternative authentication mechanism as a
complement to the TOE is available. This alternative authentication
mechanism can be used in cases where a user is rejected by the biometric
verification system (False Rejection). It is assumed that this
alternative mechanism reaches at least the same level of security as the
biometric authentication mechanism.

#### A.Protection

It is assumed that the TOE environment ensure that biometric data is
adequately protected.

Security Objectives
===================

Security Objectives for the TOE
-------------------------------

#### O.BIO\_Verification

The TOE shall provide a biometric verification mechanism to control
access to the protected services with an adequate reliability. The TOE
shall meet relevant criteria for its security relevant error rates for
biometric verification.

#### O.Presentation\_Attack\_Detection

The TOE shall prevent a presentation attack using Presentation Attack
Instrument (PAI). The TOE shall meet relevant criteria for its security
relevant error rates for PAD

#### O.Enrol

The TOE shall implement the functionality to enroll users for biometric
verification, only after successful authentication of a user. The TOE
shall check the quality of enrolment templates in order to meet the
requirements on recognition performance.

Security Objectives for the Operational Environment
---------------------------------------------------

#### OE.TrialLimit

The TOE environment shall be able to limit the maximum number of
unsuccessful verification attempts.

#### OE.User

The user will configure the device correctly in a manner to ensure that
the TOE security policies will be enforced.

#### OE.Alternative

Alternative authentication mechanism as a complement to the TOE will be
available. This alternative authentication mechanism can be used in
cases where a user is rejected by the biometric verification system
(False Rejection). This alternative mechanism will reach at least the
same level of security as the biometric authentication mechanism.

#### OE.Protection

The TOE environment shall ensure that biometric data is adequately
protected.

Note: Biometric data can be stored in the filesystem and reside in the
memory. All such data shall be protected from unauthorized access or
deleted after its use.

Security Objectives Rationale
-----------------------------

This section describes how the assumptions, threats, and organizational
security policies map to the security objectives.

  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Threat, Assumption, or OSP   Security Objectives                 Rationale
  ---------------------------- ----------------------------------- -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  T.Casual\_Attack             O.BIO\_Verification                 The threat T.Casual\_Attack is countered by O.BIO\_Verification as this provides the capability of biometric verification not to allow users who have not been enrolled access to the protected services.
                                                                   
  OSP.Verification\_Error                                          The OSP OSP.Verification\_Error is enforced by O.BIO\_Verificaiton as this require the TOE to meet relevant criteria for security relevant error rates for biometric authentication

  T.Presentation\_Attack       O.Presentation\_Attack\_Detection   The threat T.Presentation\_Attack is countered by O.Presentation\_Attack\_Detection as this provides the capability of biometric verification to prevent attacks with PAI.
                                                                   
  OSP.PAD\_Error                                                   The OSP OSP.PAD\_Error is enforced by O.Presentation\_Attack\_Detection as this require the TOE to meet relevant criteria for security relevant error rates for PAD

  OSP.Enrol                    O.Enrol                             The OSP OSP.Enrol is enforced by O.Enrol as this require the TOE to implement the functionality to enroll users for biometric verification and check quality of enrolment templates

  OSP.TrialLimit               OE.TrialLimit                       The OSP OSP.TrialLimit is enforced by the operational environment objective OE.TrialLimit

  A.User                       OE.User                             The Assumption A.User is satisfied by the operational environment objective OE.User

  A.Alternative                OE.Alternative                      The Assumption A.Alternative is satisfied by the operational environment objective OE. Alternative

  A.Protection                 OE.Protection                       The Assumption A.Protection is satisfied by the operational environment objective OE.Protection
  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Security Requirements
=====================

Security Fundamental Requirements
---------------------------------

### Class: Identification and Authentication (FIA)

#### FIA\_BVR\_EXT.2 Timing of the user authentication with biometric verification

**FIA\_BVR\_EXT.2.1** The TSF shall allow \[assignment: list of TSF
mediated actions\] on behalf of the user to be performed before the user
is authenticated with biometric verification.

**FIA\_BVR\_EXT.2.2** The TSF shall provide a user authentication
mechanism with to the user with the \[selection: FMR, FAR\] not
exceeding \[assignment: defined value\] and \[selection: FNMR, FRR\] not
exceeding \[assignment: defined value\] to require each user to be
successfully authenticated before allowing any other TSF-mediated
actions on behalf of that user.

Application note:

The ST author should follow the technical terms defined in the Annex A.

Value of FMR, FAR, FNMR and FRR can be assigned by the ST author however
the ST author should consider the following factors.

1)  Required minimum values defined in the standards

For example, NIST Special Publication 800-63B requires that FMR shall be
1 in 1000 or lower. ISO/IEC 21879 proposes that FAR would be 1 in 10000
or lower that is equal to a conventional four-digit PIN-Code for secure
transaction. The ST author should consider those values when they assign
the target performance values.

For consistency in language throughout this document, referring to a
“lower” number will mean the chance of occurrence is lower (i.e. 1/100
is lower than 1/20). So, saying device 1 has a lower FAR than device 2
means device 1 could have 1/1000 and device 2 would be 1/999 or higher
in terms of likelihood. Saying “greater” will explicitly mean the
opposite.

1)  Technical limitation

Several modalities are used for the mobile biometric verification. Some
modalities are easier to use for users however they can’t achieve the
same level of performance because of the technical limitation. For
modalities that have different performance levels, the requirement can
be iterated to make the associated levels and claims clear for each
modality.

1)  Number of test subjects required for the performance testing

Target performance value will directly influence the size of the test
subject, the time and the cost of the testing.

The following table gives examples of number of test subject required
for various FAR target based on Rule of 3 and Rule of 30. These rules
are not mandatory requirement for this cPP however evaluating the better
performance needs more test subjects.

![](media/image1.emf){width="5.905555555555556in"
height="2.202458442694663in"}

#### Evaluation Activity for FIA\_BVR\_EXT.2.1

Note: Format of evaluation activities follows 1^st^ WD 15408-4 and may
be modified through the discussion at the ISO meetings.

a)  **Objective of the evaluation activity**

The evaluator shall verify that the TOE allows only listed actions in
the assignment before the biometric verification.

a)  **Relationship of the evaluation activity to SFRs, SARs, and other
    evaluation activities**

This evaluation activity can supplement all work units defined in
ATE\_IND.1 for testing the FIA\_BVR\_EXT.2.1.

This evaluation activity doesn’t have any dependencies to other
evaluation activities defined in this cPP.

a)  **Tools required to perform the activity**

No tools are required to perform this evaluation activity.

a)  **Required input from the developer or other entities**

Security Target.

TSS shall list all actions allowed before the biometric verification.

a)  **Assessment Strategy**

The evaluator shall verify that the TSS describes the actions allowed by
unauthorized users in the locked state (i.e. before the biometric
verification). The evaluator shall attempt to perform actions not listed
in the assignment while the device is in the locked state and verify
that those actions do not succeed.

a)  **Pass/fail criteria**

The evaluators can pass this evaluation activity if:

-   all actions allowed in the locked state are described in the TSS

-   any other actions can’t be performed by the evaluators before the
    biometric verification

#### Evaluation Activity for FIA\_BVR\_EXT.2.2

a)  **Objective of the evaluation activity**

Target values (i.e. “defined value” in the assignment of
FIA\_BVR\_EXT.2.2) of FAR/FMR and FRR/FNMR specified in the
FIA\_BVR\_EXT.2 shall be equal or larger than ones measured by the TOE
developer’s performance testing.

Performance test document shall be provided to the evaluators and
evaluators shall examine the document to check FAR/FMR and FRR/FNMR are
measured correctly. Assessment strategy explains how to check the
document in detail.

This cPP assumes that TOE’s biometric verification is not used for
security sensitive services such as mobile banking and the TOE
environment limits the maximum number of verification attempts.
Therefore, risk of zero effort attacks is low and the performance may
not be needed to be measured based on statistical method (e.g. Rule of 3
or Rule of 30) by the developer’s performance testing. However
statistical method may be used to measure FAR/FMR and FRR/FNMR if
possible.

a)  **Relationship of the evaluation activity to SFRs, SARs, and other
    evaluation activities**

This evaluation activity can supplement all work units defined in
ATE\_FUN.1 for evaluating the FIA\_BVR\_EXT.2.1 (i.e. developer’s
performance testing).

This evaluation activity doesn’t have any dependencies to other
evaluation activities defined in this cPP.

a)  **Tools required to perform the activity**

No tools are required to perform this evaluation activity.

a)  **Required input from the developer or other entities**

Security Target and developer’s performance test document.

This cPP doesn’t claim to satisfy ATE\_FUN.1 so document for testing the
other SFRs is not required.

a)  **Assessment Strategy**

Minimum requirements for conducting the correct or reliable performance
testing are described in Annex B. Developers shall follow these
requirements to conduct the performance testing and report the result in
the test documents. The evaluators shall confirm that the test document
provided meets all requirements in Annex B and seek a rationale if the
test document doesn’t meet those requirements.

The Annex B does not define any criteria for what the valid rationale
is. However, the evaluators should keep in mind that the objective of
this evaluation activity is not verifying that the developer’s
performance testing confirms to all requirements defined in the Annex B
or ISO/IEC 19795. This cPP assumes that the risk of the zero effort
attack is low and evaluator’s independent performance testing is not
necessary to measure FAR/FMR and FRR/FNMR objectively.

The evaluators shall also confirm that ST and the test document is
consistent (e.g. TOE identification information)

a)  **Pass/fail criteria**

The evaluator can pass this evaluation activity if:

-   test document meets the requirements in Annex B

-   valid rationale is provided if the document doesn’t meet any
    requirements

-   any information described in both security target and test document
    is consistent

#### FIA\_BVR\_EXT.4 Biometric verification not accepting presentation attack instruments

**FIA\_BVR\_EXT.4.1** The TSF shall prevent presentation of biometric
characteristics, which result in biometric samples of low quality, from
being successful in the biometric verification.

**FIA\_BVR\_EXT.4.2** The TSF shall perform testing to detect artificial
presentation attack instruments during the biometric verification.

#### Evaluation Activity for FIA\_BVR\_EXT.4.1

a)  **Objective of the evaluation activity**

Biometric performance depends on quality of samples presented to the TOE
so the TOE needs to check the quality before accepting them. Evaluator
shall examine the assessment criteria on which the TOE bases its
determination to reject or accept the samples. Evaluator shall also
perform testing to verify that the TOE rejects samples that doesn’t meet
the assessment criteria.

Evaluator shall keep in mind that different biometric characteristics
utilize different assessment criteria and the assessment criteria used
for biometric enrolment and verification may not be the same.

a)  **Relationship of the evaluation activity to SFRs, SARs, and other
    evaluation activities**

This evaluation activity can supplement all work units defined in
ATE\_IND.1 for testing the FIA\_BVR\_EXT.4.1.

This evaluation activity doesn’t have any dependencies to other
evaluation activities defined in this cPP.

a)  **Tools required to perform the activity**

Test platform to export TOE’s internal information (e.g. quality scores)

a)  **Required input from the developer or other entities**

Security Target

a)  **Assessment Strategy**

The evaluator shall examine that the TSS describes the following items,
and verify that the TOE rejects low quality samples based on its
assessment criteria.

-   quality requirements for the biometric sample in order to ensure
    that a sufficient amount of information is available

-   method to quantify the quality of samples (e.g. method to generate
    quality score)

-   assessment criteria to accept the sample of sufficient utility (e.g.
    compare quality score to quality threshold)

-   quality standard that the TOE uses to perform the assessment if the
    TOE follows such standard

The evaluator shall also perform the following testing to verify that
the TOE’s quality assessment works correctly.

*Quality check test for biometric samples for biometric verification*

The following tests require the developer to provide access to a test
platform that provides the evaluator with tools that are typically not
found on factory products.

Step 1: The evaluator shall enroll a user for each biometric modality
supported.

Step 2: The evaluator shall then input biometric samples of low quality
for verification that don’t satisfy the assessment criteria.

Step 3: The evaluator shall check the TOE internal data (e.g. quality
scores and quality threshold) to confirm that biometric samples that
don’t meet the assessment criteria are rejected.

a)  **Pass/fail criteria**

The evaluators can pass this evaluation activity if:

-   information necessary to conduct the testing is described in the TSS

-   any biometric samples that don’t meet the assessment criteria are
    rejected

#### Evaluation Activity for FIA\_BVR\_EXT.4.2

a)  **Objective of the evaluation activity**

Evaluator shall examine that the TOE is resistant to attacks with
artificial presentation attack instruments by an attacker possessing a
Basic attack potential. Use case assumed in this cPP is unlocking the
mobile device and the device is not supposed to be used for security
sensitive services such as mobile banking. Therefore, this cPP assumes
that the attacker’s motivation is not so high and they execute attacks
simply following scripts (i.e. step by step guide (e.g. demo on YouTube)
to create the PAI and run the attack with those PAI) that are publicly
available, however if the attackers recognizes that it takes too much
time and cost to follow the scripts, they would simply give up attacking
the TOE.

PAIs produced under the same script using the same biometric
characteristic may not be the same because, for example, thickness or
temperature of the PAIs, which may affect the performance of the PAI,
may vary. Attacker would run the attacks several times varying such
parameter randomly if information about the parameters is not available
in the script, however they would not try to produce all possible PAIs
because it’s far beyond the attackers’ motivation.

Evaluator shall test the TOE based on this assumption and whole
penetration testing including planning should be done within two
man-weeks. Cost of making PAIs should be less than several hundreds of
dollars.

a)  **Relationship of the evaluation activity to SFRs, SARs, and other
    evaluation activities**

This evaluation activity can supplement all work units defined in
AVA\_VAN.1 for testing the FIA\_BVR\_EXT.4.1.

This evaluation activity doesn’t have any dependencies to other
evaluation activities defined in this cPP.

a)  **Tools required to perform the activity**

Any tools can be used however total cost of tool should be less than
several hundreds of dollars

a)  **Required input from the developer or other entities**

Developer may describe how the PAD works in the TSS which may not be
included in the public version of the ST so that evaluators can filter
out some of the scripts. For examples, in the case of face recognition
the TOE may detect the motion cues (e.g. eye blinking) for liveness
checking. If evaluators can gain such information from the TSS,
evaluators can lower the priority of, for examples, attacking the TOE
using still face images.

a)  **Assessment Strategy**

This cPP assumes that attack potential for the attacker is not so high
and the following assumptions can be made for the attackers:

1)  Attackers would look for the scripts from the publicly available
    information to try the presentation attacks. Scripts define the
    procedure about how to create the PAI and run the attack with those
    PAI.

2)  If there are too many scripts available, attackers would make a
    priority to run the attack efficiently. Attackers would make the
    priority based on:

    -   level of detail of script

If the instructions in the script is clear and detailed, it’s easy for
attacker to run the attacks

-   cost of running the attack

If the attack can be executed with little cost, time and effort, the
attacker would simply try them

-   Creditability of scripts

Author of the script, number of research papers that refer the script or
the result of past testing based on the script may relate to the
creditability of the script.

-   probability of success of attacks

If the information of the TOE PAD function is publicly available
through, for examples, product manual, research paper and patent
information published by the TOE developer, the attacker would refer
such information to avoid those attacks that could be blocked by the TOE
PAD function.

-   Freshness of the attack information

If the scripts were published several years ago before the TOE released,
the TOE may have implemented countermeasure against such attacks.
However, the TOE may not counter the scripts that were published after
the TOE was released.

Attackers would simply run the scripts without modification based on the
priority. If they can’t follow the instructions in the script because
of, for examples, lack of information, they would simply give up and try
next script.

1)  If there are a few scripts available, attackers would try to modify
    the script (for example, use different materials to make the PAI) to
    attack the TOE. However, such modification shall be done within the
    limit of attacker’s time and resources (see below)

2)  If attackers can’t break the TOE within the two man-weeks including
    planning, making the PAI and attacking the TOE, they would give up
    attacking the TOE. They would not spend more than several hundreds
    of dollars in total to buy or rent tools or materials to run the
    attack however they would try to minimize the cost (e.g. if
    attackers want to use 3D printer, they may rent the 3D printer
    rather than buying it)

This cPP define Assumption A.User and evaluators shall assume that the
mobile devices are configured securely by users. Especially evaluators
shall make the following assumptions:

1)  A user enroll him/herself following guidance provided by the TOE

2)  Mobile device is securely configured and maximum number of
    unsuccessful biometric authentication attempts is limited. If the
    mobile device was evaluated based on a PP (e.g. MDF PP), maximum
    number of unsuccessful biometric authentication attempts can be
    derived from the ST that claim a conformance to the PP

This cPP defines A.Protection and evaluators shall assume that biometric
data is adequately protected. Especially evaluators shall make the
following assumptions:

1)  Attacker can’t access to the result of PAD subsystem so they can’t
    tune the PAI based on the PAD result

2)  Attacker can’t gain the templates from the TOE or mobile device to
    create the PAIs

However, evaluator can allow relax the above assumption to expedite the
penetration testing:

1)  Evaluators can enroll themselves following the guidance provided the
    TOE and use their own biometric characteristic to create the PAIs.
    However, in an actual environment, it may be difficult to steal
    biometric characteristics (e.g. iris or vein image) from the device
    owner and this difficulty shall be taken into consideration when
    evaluators rate the attack potential. Evaluators shall refer the
    table A.1 in Annex C to rate the attack potential.

2)  Evaluator can change the configuration of the mobile devices to
    increase the maximum number of unsuccessful biometric authentication
    attempts to repeat the attacks efficiently. However, in an actual
    environment, attack needs to be succeeded within the allowed number
    of biometric authentication attempts. If the evaluator can succeed
    to break the TOE but he/she always needs several attempts to tune
    the PAI and such number of attempts is greater than the allowed
    number of attempts, such attack can be excluded for consideration
    because the attack is not applicable in the actual operational
    environment of the TOE.

Evaluators shall follow assumptions and condition described above to
conduct the penetration testing. However, evaluators shall utilize their
own experiences and knowledge to conduct the testing assuming the
worst-case scenario (i.e. attacker without such skill choose best
parameters (e.g. thickness, moisture or temperature of PAI) by luck to
create the PAI) however such evaluator’s skill shall be considered to
rate the attack potential if the attack succeeds. If the attack
succeeds, evaluator shall repeat the test to make sure that the result
of attack is reproducible.

The evaluator can also consider synthesized biometric samples with
abnormal characteristic that produce high false acceptance rates only if
the scripts that can be referred to create such synthesized samples are
publicly available and cost and effort to create such samples is not
beyond the Basic attack potential.

Evaluators shall report the result of the testing referring the Annex D.
Annex D defines minimum reporting items that assure the reproducibility
of the test result.

a)  **Pass/fail criteria**

This cPP assumes that the TOE encompass PAD, data capture and comparison
subsystem. To succeed the attack, evaluators shall create artificial
PAIs that will defeat both the PAD, data capture and comparison
subsystem, which means that PAI needs to pass the quality check, contain
extractable features and matching score between feature and template
must be greater than the threshold. So, the evaluators can pass this
evaluation activity if:

-   evaluator can’t create any PAIs that falsely match enrolled target
    user assuming the Basic attack potential

#### FIA\_EBR.EXT.1 Check of biometric samples for enrolment 

**FIA\_EBR\_EXT.1.1** The TSF shall prevent use of biometric
characteristics of low quality for enrolment that has been presented by
any user of the TSF.

#### Evaluation Activity for FIA\_EBR\_EXT.1.1

a)  **Objective of the evaluation activity**

The objective of the evaluation activity is same as the objective of
FIA\_BVR\_EXT.4.1. However, FIA\_EBR\_EXT.1.1 defines the requirement
for the templates. The TOE needs to generate enrolment templates and/or
authentication templates of sufficient quality. Evaluator shall examine
the assessment criteria for both templates to verify that the TOE
rejects low quality of templates.

a)  **Relationship of the evaluation activity to SFRs, SARs, and other
    evaluation activities**

See FIA\_BVR\_EXT.4.1

a)  **Tools required to perform the activity**

See FIA\_BVR\_EXT.4.1

a)  **Required input from the developer or other entities**

See FIA\_BVR\_EXT.4.1

a)  **Assessment Strategy**

The same assessment strategy of FIA\_BVR\_EXT.4.1 shall be applied to
the biometric samples used to generate the enrolment templates.

If the TOE creates authentication templates using multiple enrollment
samples and enrolment templates, the evaluator shall examine that the
TSS describes the following items and verify that the TOE generates
authenticate templates of sufficient quality based on its assessment
criteria.

-   quality requirements for the enrolment samples to be used to adapt
    authenticate templates

-   method to quantify the quality of enrolment samples (e.g. method to
    generate quality score)

-   method to adapt authenticate templates and assessment criteria to
    generate the authenticate template of sufficient utility (e.g.
    compare quality score to quality threshold)

The evaluator shall keep in mind that the assessment criteria for
biometric samples to be used for biometric verification and ones to be
used to adapt templates may be different.

The evaluator shall also verify that the AGD guidance describes how to
enroll a user for each biometric modality supported.

The evaluator shall also perform the following testing to verify that
the TOE’s quality assessment works correctly.

*Quality check test for biometric samples for enrolment templates*

The following tests require the developer to provide access to a test
platform that provides the evaluator with tools that are typically not
found on factory products.

Step 1: The evaluator shall input biometric samples of low quality for
enrolment that don’t satisfy the assessment criteria.

Step 2: The evaluator shall check the TOE internal data (e.g. quality
scores and quality threshold) to confirm that the enrolment templates
that don’t meet the assessment criteria aren’t generated.

*Quality check test for biometric samples for authentication templates*

The following tests require the developer to provide access to a test
platform that provides the evaluator with tools that are typically not
found on factory products.

Step 1: The evaluator shall input biometric samples for biometric
verification.

Step 2: The evaluator shall check the TOE internal data (e.g. quality
scores and quality threshold) to confirm that:

-   the biometric samples that don’t meet the assessment criteria are
    not used to adapt template

-   authenticate templates adapted meet the assessment criteria to keep
    sufficient quality

a)  **Pass/fail criteria**

The evaluators can pass this evaluation activity if:

-   information necessary to conduct the testing is described in the TSS

-   any template that don’t meet the assessment criteria were not
    generated

-   AGD guidance describes how to enroll a user

Optional Security Fundamental Requirements
------------------------------------------

SFR for PAD during the enrollment (e.g. The TSF shall perform
Presentation Attack Detection testing on each biometric enrollment) will
be added here.

[]{#_Toc496619706 .anchor}Annex A

This Annex describes fundamental concept of the biometric performance
based on the ISO/IEC 19795-1:2006 Biometric performance testing and
reporting - Part 1: Principles and framework.

1.  Transactions, attempt and presentation

In typical situation for finger print verification, a user places a
finger on the sensor and the sensor captures and submits biometric
samples to the signal processing subsystem to process them for, for
example, checking the quality. The TOE may allow a sequence of attempts
for enrolment and biometric verification. ISO/IEC 19795-1 defines the
following terms to describe each level of action.

Presentation: submission of a single biometric sample on the part of a
user

Attempt: submission of one (or a sequence of) biometric samples to the
system

NOTE An attempt results in an enrolment template, a matching score (or
scores), or possibly a failure–to-acquire.

Transaction: sequence of attempts on the part of a user for the purposes
of an enrolment and verification.

NOTE There are three types of transaction: enrolment sequence, resulting
in an enrolment or a failure-to-enrol; a verification sequence resulting
in a verification decision.

For example, TOE may process a sequence of samples in a single attempt,
for example:

\(a) collecting samples over some fixed period to find the best matching
sample;

\(b) collecting samples until either a match is obtained or the system
times out; or

\(c) collecting samples until one of sufficient quality is obtained, or
the system times out.

TOE’s decision policy may allow, for example, three attempts to verify;
then the transaction may consist of one attempt, two attempts if the
first attempt is rejected, or three attempts if the first two attempts
are rejected.

1.  Performance matrices

To evaluate how accurate the TOE is, i.e. to measure the TOE biometric
performance, different metrics can be used to rate the performance.
These rates are presented at the attempt and transaction levels.

Attempt-level performance is based on results from each comparison,
measuring accuracy without consideration of a multi-attempt decision
policy. Acquisition failures that the TOE fails to capture or locate an
image or signal of sufficient quality is excluded from attempts and this
attempt-level performance measures the performance of matching component
or algorithm of the TOE.

ISO/IEC 19795-1 defines the following matrices for the attempt-level
performance.

FNMR (False Non-Match Rate): proportion of genuine attempt samples
falsely declared not to match the template of the same characteristic
from the same user supplying the sample

FMR (False Match Rate): proportion of zero-effort impostor attempt
samples falsely declared to match the compared non-self template.

On the other hand, transactional-level performance reflect performance
in applications wherein multiple match attempts are permitted within
each transaction. This is consistent with the use of biometrics in many
applications. Acquisition failures are included in the attempts and this
transaction-level performance measures the performance of the entire
TOE.

ISO/IEC 19795-1 defines the following matrices for the transaction-level
performance.

FRR (False Reject Rate): proportion of verification transactions with
truthful claims of identity that are incorrectly denied

FAR (False Accept Rate): proportion of verification transactions with
wrongful claims of identity that are incorrectly confirmed

FRR are lower than FNMR, because a test subject is more likely to match
when given multiple attempts. For the same reason, FAR are higher than
FMR.

FTA (Failure-To-Acquire rate) is not the target of the evaluation of
this cPP however this matrix is used to derive the other target
performance matrices. FTA is defined as follows.

FTA: proportion of verification or identification attempts for which the
system fails to capture or locate an image or signal of sufficient
quality

1.  Calculation methods

Each performance matrix can be calculated based on the following
equation. This cPP assumes that the same parameters (e.g. decision
threshold and image quality threshold) are used throughout the
performance testing.

1.  FNMR

Total number of genuine attempts and non-matched genuine attempts can be
calculated as follows.

The following assumes that:

-   each test subject has the same number of body parts (e.g. index and
    middle finger of right hand)

-   all body parts of all test subjects are enrolled and templates of
    all body parts are generated

-   same number of attempts (acquisition failures are excluded) are made
    for each body part (i.e. online testing), or same number of samples
    are acquired and compared later against templates (i.e. offline
    testing)

Number of test subjects: i = 1, … , N

Number of body parts of each test subject: j = 1, … , M

Number of genuine attempts made for each body part k = 1, … , O

D~ij,\ ijk~ is the matrix that shows the result of matching decision
between the template of jth body part of ith test subject and the kth
attempt/sample of jth body part of ith test subject.

$$Dij,ijk = \left\{ \begin{matrix}
1,\ \ \&\ non - match \\
0,\ \ \&\ otherwise \\
\end{matrix} \right.\ $$

**Total number of genuine attempts = N X M X O**

**Total number of non-matched genuine attempts =**
$\sum_{\mathbf{i = 1}}^{\mathbf{N}}\mathbf{\ }\sum_{\mathbf{j = i}}^{\mathbf{M}}\mathbf{\ }\sum_{\mathbf{k = i}}^{\mathbf{O}}\mathbf{D}_{\mathbf{ij,\ \ ijk}}$

1.  FMR

Total number of imposter attempts and mismatched imposter attempts can
be calculated as follows.

The following assumes that:

-   each test subject has the same number of body parts (e.g. index and
    middle finger of right hand)

-   all body parts of all test subjects are enrolled and templates of
    all body parts are generated

-   same number of samples are acquired from each body part and
    cross-matched against non-self templates (i.e. offline testing).
    Intra-individual comparisons (comparison between one body part and
    another body part of the same test subject) are excluded.

-   symmetric comparison (Both the comparison pair (T~ij~ (template of
    jth body part of ith test subject), S~kl~ (samples of lth body part
    of kth test subject)) and (T~kl~, S~ij~) are considered distinctly)
    are done

Number of test subjects: i or k = 1, … , N

Number of body parts of each test subject: j or l = 1, … , M

Number of samples acquired from each body part m = 1, … , O

D~ij,\ klm~ is the matrix that shows the result of matching decision
between the templates of jth body part of ith test subject and mth
sample of lth body part of kth test subject.

$$Dij,klm = \left\{ \begin{matrix}
1,\ \ \&\ i \neq \text{k\ and\ mismatch} \\
0,\ \ \&\ otherwise \\
\end{matrix} \right.\ $$

**Total number of imposter attempts = N X (N-1) X M^2^ X O**

**Total number of mismatched imposter attempts =**
$\sum_{\mathbf{i,k = 1}}^{\mathbf{N}}\mathbf{\ }\sum_{\mathbf{j,l = 1}}^{\mathbf{M}}\mathbf{\ }\sum_{\mathbf{m = 1}}^{\mathbf{O}}\mathbf{D}_{\mathbf{ij,klm}}$

1.  FRR

Total number of genuine and failed genuine transactions can be
calculated as follows.

The following assumes that:

-   each test subject has the same number of body parts (e.g. index and
    middle finger of right hand)

-   all body parts of all test subjects are enrolled and templates of
    all body parts are generated

-   only one genuine transaction (acquisition failures can occur within
    the transaction) are executed for each body part.

-   genuine transaction is failed if all attempts in the transaction are
    non-match or acquisition failures.

Number of test subjects: i = 1, … , N

Number of body parts of each test subject: j = 1, … , M

D~ij~ is the matrix that shows the result of genuine transaction
decision

$$Dij = \left\{ \begin{matrix}
1,\ \ \&\ falsely\ rejected\ transaction \\
0,\ \ \&\ otherwise \\
\end{matrix} \right.\ $$

**Total number of genuine transactions = N X M**

**Total number of failed genuine attempts =**
$\sum_{\mathbf{i = 1}}^{\mathbf{N}}\mathbf{\ }\sum_{\mathbf{j = i}}^{\mathbf{M}}\mathbf{D}_{\mathbf{\text{ij}}}$

1.  FAR

Total number of imposter and falsely accepted imposter transactions can
be calculated as follows.

The following assumes that:

-   each test subject has the same number of body parts (e.g. index and
    middle finger of right hand)

-   all body parts of all test subjects are enrolled and templates of
    all body parts are generated

-   only one imposter transaction (acquisition failures can occur within
    the transaction) are executed among each body part against non-self
    templates. Intra-individual comparisons (comparison between one body
    part and another body part of the same test subject) are excluded

-   symmetric comparison (Both the comparison pair (T~ij~ (template of
    jth body part of ith test subject), S~kl~ (samples of lth body part
    of kth test subject)) and (T~kl~, S~ij~) are considered distinctly)
    are done

-   imposter transaction falsely accepted if any attempts in the
    transaction are mismatched

Number of test subjects: i or k = 1, … , N

Number of body parts of each test subject: j or l = 1, … , M

D~ij,\ kl~ is the matrix that shows the result of imposter transaction
decision between the template of jth body part of ith test subject and
lth body part of kth test subject.

$$Dij,kl = \left\{ \begin{matrix}
1,\ \ \&\ i \neq \text{k\ and\ match} \\
0,\ \ \&\ otherwise \\
\end{matrix} \right.\ $$

**Total number of imposter attempts = N X (N-1) X M**

**Total number of mismatched imposter attempts =**
$\sum_{\mathbf{i,k = 1}}^{\mathbf{N}}\mathbf{\ }\sum_{\mathbf{j}\mathbf{,}\mathbf{l = 1}}^{\mathbf{M}}\mathbf{D}_{\mathbf{ij,kl}}$

1.  Relation between attempt-level and transaction level performance

    1.  FNMR and FRR

If a verification transaction consists of a single attempt, then the
attempt has to be acquisition failure or non-match, and the FRR would be
given by:

FRR = FTA + FNMR \* (1 – FTA)

If a verification transaction consists of n attempts, all attempts have
to be acquisition failure or non-match, and the FRR would be given by:

FRR = (FTA + FNMR \* (1 – FTA))^n^

1.  FMR and FAR

If a verification transaction consists of a single attempt, then the
attempt has not to be acquisition failure and non-match (i.e.
mismatched), and the FAR would be given by:

FAR = FMR \* (1 – FTA)

If a verification transaction consists of n attempts, at least one
attempts have to be mismatched and the FAR would be given by:

FAR = $\sum_{\mathbf{i = 1}}^{\mathbf{n}}\mathbf{\ }$~n~C~i~ ((FMR \* (1
– FTA))^i^ X (1 – (FMR \* (1 – FTA)))^n-i^

1.  Expression of performance metrics

Performance metrics can be expressed in many ways, e.g. in percent (1%),
ratio (1:100), decimal format (0.01) or fractions (1/100). In this cPP,
however, metrics shall be expressed in percent or ratio in the security
functional component (i.e. FIA\_BVR\_EXT.2) to keep consistency among
different STs that claim a conformance to this cPP.

Target performance matrices can be measured following methods defined in
the Annex B, “5 Accuracy of the measured performance metrics”. ST
authors need to refer this chapter when they specify the target
performance values in the security functional component.

[]{#_Toc496619707 .anchor}Annex B

This Annex describes requirements for the TOE developer’s biometric
performance testing.

Developers need to create a test plan for performance testing, execute
the test and report the result of test. Evaluators shall examine that
the performance test document satisfies the requirements to make sure
that the target value of performance metrics specified in the SFR is
achieved.

This document refers following international standards.

ISO/IEC 19795-1:2006 Biometric performance testing and reporting - Part
1: Principles and framework

ISO/IEC 19795-2:2007 Biometric performance testing and reporting - Part
2: Testing methodologies for technology and scenario evaluation.

1\. Developer’s task

1.1 Overview

Developers shall provide an evidence for biometric performance testing
(hereafter “test document”) for CC evaluations. Test document normally
consists of the following two parts.

\(1) Biometric performance test plan: a document created before
conducting performance testing, which specifies procedures for test
preparation, execution and analyzing the test result.

\(2) Biometric performance test report: a document created after the
testing, which provides result of performance test conducted based on
the performance test plan.

This Annex defines items that shall be described in the test document.

1.2 Overview of reporting items

Table-1 shows items that should be described in the test document. Name
or structure of test document doesn’t need to follow this document.
Developer’s test plan and report may be documented separately or merged
into one document, and are not required to follow the order shown in
Table-1. However, items defined in this Annex shall be written somewhere
in the test document. Also, if some items are not included in the test
document, the developer shall provide a rationale for such exclusion to
evaluators.

\(1) Reporting items

The following items shall be reported in the test document.

  Paragraph   Item
  ----------- --------------------------------------------
  1.3.1       Overview of the performance testing
  1.3.2       Target application and influential factors
  1.3.3       Test subject selection
  1.3.4       Test instructions and training
  1.3.5       Test subject management
  1.3.6       Test procedure

Table-1: Reporting items

1.3 Reporting items description

This sub paragraph describes each reporting item in detail. All items
are created based on ISO/IEC 19795-1 and 19795-2 however some of them
are modified to fit to the CC evaluation.

1.3.1 Overview of the performance testing

Developer shall report following general information about the
performance testing.

(1) Performance test configuration

> Test document shall report the following information to uniquely
> identify the test configuration of the performance testing.
> Information stated here shall be consistent with the security target.

1.  TOE reference

> Information that uniquely identify the TOE (e.g., product name,
> version, product code)
>
> Note: Modification to the TOE for performance testing, if any, shall
> be reported (e.g. The TOE is modified to export biometric data for
> off-line testing). The rationale that such modification doesn’t affect
> the TOE performance shall also be provided (e.g. Performance is not
> affected because modified code isn’t executed during the matching
> decision)

1.  TOE configuration

> Any configurable parameters or setting of the TOE that may affect the
> performance shall be reported. Value of each parameter set for the
> testing shall also be provided. For example, if threshold (e.g.
> decision threshold and image quality threshold) is configurable by
> users, value of threshold set for the testing shall be reported.

1.  TOE operational environment

> Information that uniquely identify any components that are necessary
> to run the TOE.

1.  Performance test tools

> Information that uniquely identify any testing tools (e.g. SDK) used
> for the performance testing.

(1) Summary of the testing

> Test document shall report the following items to provide the summary
> of testing.

1.  Biometric verification method

> Biometric characteristic (e.g. hand vein) and body parts (e.g. right
> and left hand) used for the TOE and overview of the matching method
> shall be reported.

1.  Number of test subjects, enrolment templates and samples

> The following variables (i.e. a), b) and c)) used for calculating the
> performance metrics shall be reported (See Annex A for the calculation
> method of each performance matrix).
>
> This Annex assumes that at least the FMR or FAR is measured through
> offline testing (i.e. cross-comparison) to achieve the maximum number
> of attempts or transactions. So, templates and samples need to be
> stored for the offline testing.
>
> Developers may collect additional templates or samples than reported
> here to increase test subjects’ familiarity with the TOE operations
> before the final testing. Developer may use the same templates or
> samples used for the final testing to run interim testing during the
> development life cycle.

a)  Test subject

> Number of test subjects who participated in the testing shall be
> reported.

a)  Enrolment templates

> Number of enrolment templates used for testing shall be reported. Only
> one enrolment template from each body part can be used for the
> testing.
>
> All test subjects cannot generate the templates successfully and total
> number of templates may be less than (number of test subjects) X
> (number of body parts of a test subject).
>
> Enrolment templates may be generated in one session or separated
> sessions with a time gap.
>
> The number of successful samples used to generate an enrolment
> template must be documented. This is the minimum number of samples
> that can be taken for each test subject’s body part.

a)  Samples

> Number of samples collected for each body part and total number of
> samples collected from all test subjects shall be reported. All test
> subjects cannot generate the samples successfully and total number of
> samples may be less than (number of test subjects) X (number of body
> parts of a test subject) X (number of samples collected for each body
> part).
>
> Samples may be collected in one session or separated sessions with a
> time gap.
>
> Number of samples collected for each body part can be determined based
> on the number of allowed attempts in one transaction or assumed
> application. If one transaction allows three attempts, three samples
> shall be collected to execute offline genuine and imposter
> transactions.

1.  Definition of genuine and imposter transaction

> Definition of a genuine and imposter transaction shall be specified if
> the developers select FAR and FRR as the target performance metrics.
> The transaction may consist of one or more attempts as allowed or
> required by the corresponding decision policy. For example, if the
> mobile device allows both a password (out of scope of the TOE) and
> biometric and it allows up to ten successive failed attempts,
> developer may assume that users try to up to eight successive
> biometric attempts without success and then switch to the password for
> the last two attempts. In this scenario, developer may define that a
> transaction is consisted of up to eight biometric attempts.
>
> If the TOE allows to enroll more than one body part (e.g. four
> fingers), test subjects can use the same body part or change the body
> part during the transaction (e.g. use the same right thumb for eight
> attempts in one transaction or use right thumb for first four attempts
> and switch to left thumb for the other four attempts in one
> transaction). However, test document shall clearly define what
> constitutes the transaction based on expected user behavior and the
> same rule needs to be applied to all transactions.
>
> Each test subject can execute multiple transactions if the TOE allows
> to enroll more than one body part. For example, if the TOE allows to
> enroll four fingers and three attempts can be made in one transaction,
> four offline genuine transactions can be executed using 3 X 4 = 12
> samples collected. However, the same sample-template pair can be used
> only once during these offline transactions.

1.  Result of testing

> Performance metrics measured following equations in Annex A shall be
> reported.

1.  Accuracy of the measured performance metrics

> Note: Some text to be added to address “*Either way there should be
> some examples or preferably minimum defined bounds for claims to be
> considered acceptable*”
>
> Test document shall report the reliability of measured performance
> metrics. The developers shall follow the rule of 3 if they see no
> error in the testing and the rule of 30 if the number of test subjects
> is large enough.
>
> It’s recommended to estimate and report the error rate of the measured
> performance metrics based on the statistical approach, however the
> developers can describe their own approach to measure the error rate
> or explain their procedure to increase the accuracy of the measured
> values.

a)  Rule of 3

> If no error occurred for all genuine or imposter transactions, Rule of
> 3 can be applied. If 300 transactions were executed without any error,
> 95 % upper confidence limit is 3/300 (or 3/(300+1)) = 1:100 or 1%.
> Target value in the assignment of the SFR shall be specified with
> statistical method used (e.g. “1% (following rule of 3)”. Target
> values in the assignment shall be the same or larger than 95 % upper
> confidence limit.
>
> This Rule of 3 assumes the binomial distribution of the error and
> neglects the correlation among transactions (e.g. correlation among
> genuine transactions using different body parts from the same test
> subject). Developer can measure the correlation among transactions to
> derive the number of required test subjects (See \[x\])) more
> precisely.

a)  Rule of 30

> If error occurred during all genuine or imposter transactions, upper
> confidence limit can be calculated if the number of test subjects is
> “large enough”. “large enough” means that 30 errors should be obtained
> from all transactions (i.e. Rule of 30).
>
> This Rule of 30 assumes the binomial distribution of the error and
> neglects the correlation among transactions (e.g. correlation among
> genuine transactions using different body parts from the same test
> subject). Developer can measure the correlation among transactions to
> derive the number of required test subjects (See \[x\])) more
> precisely.
>
> Target values in the assignment of the SFR shall be specified with
> statistical method used (e.g. “1% (following rule of 30)”. The target
> value in the assignment shall be the same or larger than 95 % upper
> confidence limit.

a)  Bootstrap method

> If the number of test subjects is not “large enough”, bootstrap method
> can be used the error rate of measured performance metrics. Bootstrap
> method is explained in \[x\] or \[x\] in detail.
>
> Target values in the assignment of the SFR shall be specified with
> statistical method used (e.g. “1% (following bootstrap method with 95%
> confidence interval)”. The target value in the assignment shall be the
> same or larger than the estimated value.
>
> Concrete procedure including number of bootstrap replicates for the
> bootstrap method used shall be reported in the test document.

a)  Developer’s own approach

> Developers may not need to follow the statistical method described
> above and may follow their own approach to measure the performance
> metrics. For example, developers may conduct several online or offline
> testing with different number of test subjects following different
> test scenarios, rather than conducting a testing with a large number
> of test subjects based on one test scenario.
>
> The overall developer’s approach for the performance testing shall be
> reported in the test document.
>
> Developers must specify their target of performance metrics in the
> assignment. If maximum number of allowed failed transactions is 10
> among 300 transactions, developer can specify those value in the
> assignment of the SFR (e.g. “10:300 (Failed transactions = 10, Total
> transactions = 300)”) and result of performance testing shall meet
> this target.

1.  Tester information

> The name and entity of the tester as well as relationships between the
> tester and the developer (independent/dependent) shall be reported.
> While most tests are assumed to be conducted by a developer’s
> employees, some part of testing such as gathering test crew may be
> conducted by another entity.

1.  Test period and location

> Timeline for data collection (i.e. samples or templates may be
> collected over multiple sessions), online or offline testing, and
> location of testing shall be reported.

1.3.2 Target application and influential factors

Test document should specify a target application modeled in the test,
such as biometric verification in an indoor office environment with a
non-habituated crew. It may not be possible to define such target if the
TOE covers the broad range of application so describing the target
application is optional.

However, test document shall report influential factors that may
influence performance, measures to control such factors and under what
factors the performance testing was conducted.

Influential factors can be determined by referring appropriate documents
(e.g. ISO/IEC 19795-3) or referring the product datasheet (e.g.
operating temperature). These factors should be consistent with the
target application.

The following factors are examples of controlling factors for
finger/hand vein verification. Developers can define these factors
arbitrarily. However, it’s recommended to control all of influential
factors appropriately because different performance metrics can be
measured under different influential factors.

(1) Test crew demographics

<!-- -->

1.  Age: age distribution ratio by arbitrary age groups (e.g., 1, 5, 10
    years) shall be reported.

2.  Gender: male/female distribution shall be reported.

3.  Ethnic origin: Distribution ratio by ethnic origin shall be
    reported. Category of ethnic origin can be arbitrarily defined by
    developer.

<!-- -->

(1) Posture and positioning

> Posture of test crew or positioning of his/her hand/finger (e.g.
> Orientation of hand/finger in relation to the sensor or distance to
> the sensor) shall be reported. Such information shall be consistent
> with the TOE operational guidance or automated feedback provided by
> the TOE.

(1) Indoor or outdoor

> Indoor or outdoor environment in which testing is to be conducted
> shall be reported. In case of outdoor environment, other factors
> affecting the performance (e.g. environmental illumination) shall also
> be reported.

(1) Temperature

> Range of temperature at which the testing is to be conducted shall be
> reported (e.g. “Testing was conducted in an air-conditioned
> environment where temperature was kept between X and Y degrees”).

(1) Time interval

> Time interval (e.g. minimum, maximum and average time) between
> enrolment and verification shall be reported.

(1) Habituation

> The degree to which the crew is familiarized with the TOE shall be
> reported (e.g. historical frequency of use of the TOE)

(1) Template adaptation

> How much template adaptation occur prior to measure the FNMR or FRR
> shall be reported if the TOE is able to adapt the templates over time
> with the aim to reduce the false rejection rates.

1.3.3 Test subject selection

Following information about test subject for the testing shall be
reported.

(1) Selection method of test subject

> Selection method shall be reported (e.g. gather test subjects from
> developer’s employees or recruit them from public).

(1) Use of artificially generated sample or features data

> The use of artificially generated data, if any, shall be reported. The
> numbers of test subjects, body parts and samples derived from
> artificially generated images or feature data along with the rationale
> for using artificial data shall be provided.

1.3.4 Test instructions and training

Instructions and training given to the test subjects shall be reported.
The same instructions and training shall be given to the all test
subjects.

(1) Acclimatization

> When a test subject enters a test room from outside for biometric data
> collection, performance may vary because of large temperature changes.
> Method of subject acclimatization to avoid such effect or the expected
> environment to handle incoming test subjects shall be reported.

(1) Test information and general test instructions

> Test information and general test instructions given to test subject
> prior or after biometric data collection shall be reported.
>
> Note: Performance testing shall be done in accordance with the
> instruction given by the TOE or TOE operational guidance (i.e. Testing
> shall not be adjusted to the TOE specification that is not described
> in the TOE operational guidance)

(1) Confirmation of habituation

> Method for how to confirm the level of subject habituation prior to
> biometric data collection shall be reported. If the habituation was
> confirmed through training, method to ensure the consistency of
> training among test subjects and the tools used for training shall be
> reported (e.g. developer can prepare the script for training in
> advance and apply it to all test subjects to ensure the consistency).

1.3.5 Test subject management

Following information about test subject management shall be reported.

(1) Management processes

> Biometric data can be corrupted by human error during the collection
> process (e.g. using a middle finger when the index finger is
> required). The test subject management processes to avoid such errors
> shall be reported. Management processes shall cover the following
> processes.

1.  method of initial test subject registration

2.  method of ensuring test subject uniqueness

3.  amount and type of personal data collected

4.  method of avoiding data collection errors (e.g. Use of data
    collection software minimizing the amount of data requiring keyboard
    entry)

1.3.6 Test procedure

A test procedure to measure performance metrics shall be reported. The
following items shall be covered

(1) Type of attempt or transaction

> Whether the attempt or transaction is executed online or offline shall
> be reported. Online means that enrolment and verification is executed
> at the time of image submission. Offline means that enrolment and
> verification is executed separately from image submission.

(1) Test flow

> The following shall be reported to explain the flow of genuine and
> imposter attempt or transaction to measure performance metrics.

1.  quality score threshold to measure performance

2.  details of test flow (e.g., flow chart)

3.  maximum duration of attempt or transaction

4.  For FNMR and FMR, number of attempts made

> For FAR and FRR, minimum and maximum number of attempts allowed for a
> transaction

1.  For FNMR and FMR, number of presentation made

> For FNMR and FMR, minimum and maximum number of presentations allowed
> for a transaction

1.  minimum number of required samples and maximum number of allowed
    samples for a transaction

<!-- -->

(1) Sample exclusion criteria

> Criteria for sample exclusion shall be reported (i.e. Test operator
> shall not manually discard nor use an automated mechanism to discard
> collected samples unless the samples conform to documented exclusion
> criteria). Number of excluded samples shall be reported. If
> transactions are failed because of such excluded samples, number of
> such failed transactions shall also be reported. These failed
> transactions shall be counted as failed transactions to calculate the
> performance metrics.

(1) Advice or remedial action for test subjects who fails a transaction

> Advices or remedial actions to test subjects who fail to complete
> transactions or data collections shall be reported including the
> following items.

1.  Advices or remedial actions provided

> Note: Advice or actions shall be consistent with that of the target
> application.

1.  Guidance policy shall be reported including

<!-- -->

a)  point(s) in a transaction at which guidance is permitted or required

b)  specific guidance a supervisor or test operator is to provide to
    test subject

c)  aspects of guidance at the discretion of the supervisor or test
    operator, if any.

<!-- -->

(1) Weighting

> If performance is estimated using a weighted proportion, the method of
> weighting shall be reported (e.g., test subject’s distribution,
> distribution of the number of executed transactions).

(1) Intra-individual comparisons for imposter transaction

> Whether intra-individual comparisons were made to measure the FNMR or
> FAR shall be reported. Intra-individual comparisons, if any, shall be
> fully explained in the test document. Intra-individual comparison is a
> comparison between one body part and another body part of the same
> test subject if the test subject has multiple body parts for a
> biometric characteristic (e.g. fingers, hands and eyes).

[]{#_Toc496619708 .anchor}Annex C

**A.3 Calculating attack potential **

Attack potential is a function of expertise, resources and motivation,
as is written in ISO/IEC 18045. Regarding motivation, see B.4.1.1 in
ISO/IEC 18045.

**A.3.1 Identification and exploitation of attacks **

**A.3.1.1 Identification of attacks **

Identification corresponds to the effort required to create the attack,
and to demonstrate that it can be successfully applied to the TOE
(including setting up or building any necessary test equipment). The
demonstration that the attack can be successfully applied needs to
consider any difficulties in expanding a result shown in the laboratory
to create a useful attack. One of the outputs from identification could
be a script that gives a step-by-step description of how to carry out
the attack. This script is assumed to be used in the exploitation phase.

**A.3.1.2 Exploitation of attacks **

Exploitation corresponds to achieving the attack on an instance of the
TOE in its exploitation environment using the analysis and techniques
defined in the identification phase. It could be assumed that a
different attacker carries out the exploitation, the technique (and
relevant background information) could be available for the exploitation
in the form of a script or set of instructions defined during the
identification phase. This type of script is assumed to identify the
necessary equipment and, for example, mathematical techniques used in
the analysis, or presentation attack methods.

Furthermore, this same information may also reduce the exploitation
requirement to one of time measurement, whereas the identification phase
may have required reverse engineering of hardware or software
information hence the expertise requirement may be reduced.

NOTE1 – For the evaluator, the work of the identification phase has to
be fully performed: developing hardware and software, creating PAIs if
any, etc. The rating of this phase corresponds to the "real spending" in
defining the attack. For the exploitation, it is not necessary to
perform the work again and the rating could correspond to an evaluation
of the necessary effort for each factor.

NOTE2 – Exploitation consisting in applying scripts, it is expected that
some factor values will be reduced from the identification phase, in
particular "Elapsed Time" and "Expertise". For the same reason, the
"Knowledge of the TOE" factor is not applicable in the exploitation
phase (all the knowledge is scripted).

**A.3.2 Factors to be considered **

As in ISO/IEC 18045, the factors to be considered consist of ***Elapsed
time, Expertise, Knowledge of the TOE, Window of opportunity, and
Equipment***. But ***Window of opportunity*** is divided into two
subfactors ***Window of opportunity (Access to the TOE)*** and ***Window
of opportunity (Access to biometric characteristics)***.

***Elapsed time*** is the total amount of time taken by the attacker.

In the identification phase, elapsed time corresponds to the time
required to create the attack, and to demonstrate that it can be
successfully applied to the TOE (including setting up or building any
necessary hardware or software equipment). The demonstration that the
attack can be successfully applied needs to consider any difficulties in
expanding a result shown in the laboratory to create a useful attack.
One of the outputs from identification is, for instance, a script that
gives a step-by-step description of how to carry out the attack. This
script is assumed to be used in the exploitation part.

In the exploitation phase, elapsed time corresponds to the time
necessary to apply the "script" to a specific biometric characteristic.
For example, for a presentation attack to a fingerprint capture device,
it corresponds to the time required to create a PAI from an image of a
print (and not the acquisition of this image which is taken into account
in the factor Window of opportunity (Access to biometric
characteristics)).

Potential difficulties to have access to the TOE in exploitation
environment are taken into account in the factor Window of opportunity
(Access to the TOE).

***Expertise*** refers to the level of proficiency required by the
attacker and the general knowledge that he possesses, not specific of
the system being attacked. The levels are as follows:

a)  Layman is the level no real expertise needed and such that any
    person with a regular level of education is capable of performing
    the attack. For example, creating a PAI in a known (published) way
    without specific difficulties (specific or difficult to buy
    materials) is considered at this level of expertise.

b)  Proficient is the level such that some advanced knowledge in certain
    specific topics (biometrics) is required as well as good knowledge
    of the state-of-the-art of attacks. An attacker of this level is
    capable of adapting known attack methods to his needs. For example,
    adapting a known attack type (published) by the choice of specific
    (not published and sometimes difficult to find) materials in order
    to bypass a presentation attack detection mechanism and/or finding a
    non-evident way to present this PAI to the system can be considered
    at this level of expertise.

c)  Expert is the level such that a specific preparation in multiple
    areas such as pattern recognition, computer vision or optimization
    is needed in order to carry out the attack. An attacker of this
    level is capable of generating his own new attacking algorithms. For
    example, finding a new (unpublished) way of creating an attack type
    using new and specific materials (unpublished) to counter an
    advanced presentation attack detection mechanism, can be considered
    at this level. In addition, this level can be associated with
    specific equipment (bespoke)

d)  Multiple experts are the level such that the attack needs the
    collaboration of several people with high level expertise in
    different fields (e.g., electronics, cryptanalysis, physics, etc.).
    It has to be noticed that a specific competence in biometrics is not
    considered as "multiple expertise". For example, building a "hill
    climbing" attack by gaining access to the comparison scores requires
    additional expertise to electrically attack and penetrate the TOE,
    which can be considered to constitute a "multi expertise" level.

NOTE1 – As previously noted, exploitation expertise is usually lower
than identification expertise. Layman or Proficient can be considered as
typical value for expertise in the exploitation phase. For the same
reason, the multiple expert level is excluded from the exploitation
phase.

NOTE2 – As all the factors, higher rating would require specific
justifications from the evaluator.

***Knowledge of the TOE*** refers to the amount of knowledge of system
required to perform the attack.

For instance, format of the acquired samples, size and resolution of
acquisition systems, specific format of templates, but also
specifications and implementation of countermeasures are knowledge that
could be required to set up an attack.

This information could be publicly available at the website of the
capture device manufacturer or protected (distributed to stakeholders
under non-disclosure agreement or even classified inside the company).
The levels are as follows:

a)  Public information which is fairly easy to obtain (e.g., on the
    web).

b)  Restricted information which is only shared by the developer and
    organizations which are using the system, usually under a
    non-disclosure agreement.

c)  Confidential information which is only available within the
    organization that develops the system and is in no case shared
    outside it.

d)  Critical information which is only available to certain people or
    groups within the organization which develops the system.

Special attention should be paid in this point to possible
countermeasures that may be implemented in the system and whether it is
necessary or not to have knowledge of their existence in order to be
successful in a given attack.

It is assumed that all the knowledge required to perform the attack is
gained during the identification phase and "scripted" for the
exploitation. Therefore, this factor is not used for the exploitation
phase.

***Window of opportunity (Access to the TOE)*** refers to measuring the
difficulty to access the TOE either to prepare the attack or to perform
it on the target system.

For the identification phase, elements that should be taken into account
include the easiness to buy the same biometric equipment (with and
without countermeasures).

For exploitation phase, both technical (such known/unknown tuning) and
organizational measures (presence of a guard, ability to physically
modify the target, limited number of tries, etc.) should be taken into
account.

The number and the level of equipment requested to build the attack is
also taken into account in this factor.

This factor is not expressed in terms of time. The levels are as
follows:

a)  Easy: For identification phase, there is no strong constraint for
    the attacker to by the TOE (reasonable price) to prepare its attack.
    For exploitation phase, there is no limit in the number of tries and
    the presentation attack is difficult to detected.

b)  Moderate: For identification phase, specialized distribution schemes
    exist (not available to individuals). For exploitation phase, either
    a tuning of the attack for the final system is required (unknown
    parameterization of countermeasures for example) or there is a
    supervision of the biometric system emitting, for example, an alert
    in case of numerous fail presentations.

c)  Difficult: For identification phase, the system is not available
    except for identified users and access requires compromising of one
    of the actors. For exploitation phase, for example PAIs must be
    adapted to the (unknown) specific tuning, or there is a strong
    supervision (for example a guard), or the system needs physical
    modification (for example physically accessing a hidden signal
    significant of the comparison score). Compromising one actor
    involved in the use of the system (guard, administrator, and
    maintenance) is often required.

***Window of opportunity (Access to biometric characteristics) ***

Security evaluations of ISO/IEC 15408 are dedicated to evaluating the
intrinsic resistance of a system. Due to the potential number of attack
paths (with or without the cooperation of an enrolled subject for
example) the evaluation does not take into account the way a real
biometric characteristic is acquired. For presentation attack detection,
the vulnerability analysis is based on the hypothesis that a real
"image" is available, and the rating only concerns the creation and the
presentation of a PAI.

However, it is important to be able to compare the resistance of various
systems, even based on different biometrics. In addition, getting a real
"image" to build a PAI is clearly part of an attack and it is of
interest, for the final user of the TOE and the pertinence of a
certificate to add a factor related to this aspect. The levels are as
follows:

a)  Immediate is for 2D face, signature image, and voice. Samples of
    these modalities can be collected without difficulty, even without
    direct contact with an enrolled data subject (an exploration of the
    web and the social networks and so forth).

b)  Easy is for fingerprint. Fingerprints are often left on objects the
    enrolled data subject had in hand, but need to be revealed, acquired
    and the corresponding images need a preprocessing.

c)  Moderate is for 3D face, dynamic signature, and 3D fingerprint. 3D
    images require multiple acquisitions, probably in a controlled way,
    without the collaboration of an enrolled data subject but probably
    with a direct contact with them.

d)  Difficult is for iris and vein. Iris images can be acquired with a
    high-resolution camera, but with some difficulties to get a complete
    high-quality image without the cooperation of an enrolled data
    subject. Veins are a hidden characteristic, but infra-red cameras,
    close to them, can acquire images to be used.

NOTE 1 – The above distribution of modalities per level is subject to
modification depending on the evolution of technologies and usage. The
current distribution is to be seen as guidance for the evaluator, who
will have to adapt the rating to state-of-the-art.

NOTE 2 – Rating the resistance of a system is based on rating the
successful attacks and verifying that no successful attack is found at
the targeted level. Some attacks do not need real biometric data to be
available, for example, attacks based on synthetic images or templates
generation. In such a case, this factor has to be considered to be
Immediate.

***Equipment*** refers to the type of equipment required to perform the
attack. This includes the biometric databases used (if any). The levels
are follows:

Standard equipment is an orderable, easy to obtain and simple to operate
equipment (e.g., computer, video cameras, mobile phones, "do it
yourself" material, and artistic leisure materials).

Specialized equipment refers to fairly expensive equipment, not
available in standard markets and which require of some specific
formation to be used (e.g., laboratory equipment, advanced printer
specific materials and inks, and advanced oscilloscopes).

Bespoke equipment refers to very expensive equipment with difficult and
controlled access; for example, research printing systems with specific
ink definition and flexible support adaptation. In addition, if more
than one specialized equipment is required to perform different parts of
the attack, this value should be used. Before using this level, it has
to be carefully checked that no service is available (renting, limited
time access, etc.). If such service exists, the level has to be moved
down to Specialized level.

**A.3.3 Calculation of attack potential **

Table A.1 identifies the factors discussed in the previous subclause and
associates numeric values with the total value of each factor.

Table A.1 — Calculation of attack potential

  -----------------------------------------------------------------------------
  Factor                                      Value
  ------------------------------------------- ---------------- ----------------
                                              Identification   Exploitation

  **Elapsed Time**                                             

  &lt;= one day                               0                0

  &lt;= one week                              1                2

  &lt;= two weeks                             2                4

  &lt;= one month                             4                8

  &gt; one month                              8                16

  **Expertise**                                                

  Layman                                      0                0

  Proficient                                  2                4

  Expert                                      4                8

  Multiple experts                            8                Not applicable

  **Knowledge of TOE**                                         

  Public                                      0                Not applicable

  Restricted                                  2                Not applicable

  Sensitive                                   4                Not applicable

  Critical                                    8                Not applicable

  **Window of Opportunity**                                    
                                                               
  **(Access to TOE)**                                          

  Easy                                        0                0

  Moderate                                    2                4

  Difficult                                   4                8

  Immediate                                   Not applicable   0

  **Window of Opportunity**                                    
                                                               
  **(Access to Biometric Characteristics)**                    

  Easy                                        Not applicable   2

  Moderate                                    Not applicable   4

  Difficult                                   Not applicable   8

  **Equipment**                                                

  Standard                                    0                0

  Specialized                                 2                4

  Bespoke                                     4                8
  -----------------------------------------------------------------------------

**A.3.4 Rating of vulnerabilities and TOE resistance **

The "Values" column of Table A.2 indicates the range of attack potential
values (calculated using Table A.1) of an attack scenario that results
in the SFRs being undermined.

Table A.2 — Rating of vulnerabilities and TOE resistance

  -----------------------------------------------------------------------------
  Values    Attack potential    TOE resistant   Meets assurance   Failure of
                                                                  
            required to         to attackers    components:       components:
                                                                  
            exploit scenario:   with attack                       
                                                                  
                                potential of:                     
  --------- ------------------- --------------- ----------------- -------------
  &lt; 10   Basic               No rating       -                 AVA\_VAN.1,
                                                                  
                                                                  AVA\_VAN.2,
                                                                  
                                                                  AVA\_VAN.3,
                                                                  
                                                                  AVA\_VAN.4,
                                                                  
                                                                  AVA\_VAN.5

  10-19     Enhanced-           Basic           AVA\_VAN.1,       AVA\_VAN.3,
                                                                  
            Basic                               AVA\_VAN.2        AVA\_VAN.4,
                                                                  
                                                                  AVA\_VAN.5

  20-29     Moderate            Enhanced-       AVA\_VAN.1,       AVA\_VAN.4,
                                                                  
                                Basic           AVA\_VAN.2,       AVA\_VAN.5
                                                                  
                                                AVA\_VAN.3        

  30-39     High                Moderate        AVA\_VAN.1,       AVA\_VAN.5
                                                                  
                                                AVA\_VAN.2,       
                                                                  
                                                AVA\_VAN.3,       
                                                                  
                                                AVA\_VAN.4        

  =&gt;40   Beyond-High         High            AVA\_VAN.1,       -
                                                                  
                                                AVA\_VAN.2,       
                                                                  
                                                AVA\_VAN.3,       
                                                                  
                                                AVA\_VAN.4,       
                                                                  
                                                AVA\_VAN.5        
  -----------------------------------------------------------------------------

[]{#_Toc496619709 .anchor}Annex D

Evaluator shall conduct the penetration testing and report the following
items in the ETR. The following reporting items are defined referring
the following ISO standard.

ISO/IEC 30107-3, Information technology – Biometric presentation attack
detection – Part 3: Testing and reporting.

1.  Reporting items

Evaluator shall conduct the penetration testing following the Assessment
strategy and report the result of testing in the ETR. ETR should include
the following items so that other evaluator can reproduce the result of
testing, especially if evaluator can succeed the attacks.

TBD
